"""
å¢¨é—® API MCP æœåŠ¡å™¨ä¸»æ–‡ä»¶

è¿™ä¸ªæœåŠ¡å™¨å°è£…äº†å¢¨é—®ç¬”è®°è½¯ä»¶çš„APIï¼Œæä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
1. åˆ›å»ºç¬”è®°ï¼ˆç»Ÿä¸€å¯Œæ–‡æœ¬æ ¼å¼ï¼‰
2. ç¼–è¾‘ç¬”è®°ï¼ˆç»Ÿä¸€å¯Œæ–‡æœ¬æ ¼å¼ï¼‰
3. è®¾ç½®ç¬”è®°æƒé™
4. é‡ç½®APIå¯†é’¥

æ‰€æœ‰ç¬”è®°æ“ä½œå‡ä½¿ç”¨ç»Ÿä¸€çš„å¯Œæ–‡æœ¬æ ¼å¼ï¼Œæ”¯æŒï¼š
- æ™®é€šæ®µè½ï¼šæ–‡æœ¬å†…å®¹å’Œå¯Œæ–‡æœ¬æ ¼å¼ï¼ˆåŠ ç²—ã€é«˜äº®ã€é“¾æ¥ï¼‰
- å¼•ç”¨æ®µè½ï¼šç”¨äºåˆ›å»ºå¼•ç”¨æ–‡æœ¬å—
- å†…é“¾ç¬”è®°ï¼šç”¨äºå¼•ç”¨å…¶ä»–ç¬”è®°ï¼Œåˆ›å»ºç¬”è®°é—´çš„å…³è”
"""

import asyncio
import json
import logging
import os
import mimetypes
import aiofiles
from pathlib import Path
from typing import Any, Dict, List, Optional, Literal
from urllib.parse import urljoin
import nest_asyncio

import httpx
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field

# å…è®¸åµŒå¥—äº‹ä»¶å¾ªç¯
nest_asyncio.apply()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("mowen-mcp-server")

# åˆ›å»ºFastMCPæœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("å¢¨é—®ç¬”è®°MCPæœåŠ¡å™¨")

class MowenAPI:
    """å¢¨é—®APIå®¢æˆ·ç«¯ç±»ï¼Œå°è£…æ‰€æœ‰APIè°ƒç”¨"""
    
    def __init__(self, api_key: str, base_url: str = "https://open.mowen.cn"):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    async def create_note(self, body: Dict[str, Any], settings: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        åˆ›å»ºç¬”è®°
        
        å‚æ•°:
        - body: ç¬”è®°å†…å®¹ï¼ˆNoteAtomç»“æ„ï¼‰
        - settings: ç¬”è®°è®¾ç½®ï¼ˆå¯é€‰ï¼‰
        """
        url = urljoin(self.base_url, "/api/open/api/v1/note/create")
        payload = {"body": body}
        if settings:
            payload["settings"] = settings
        
        # è®°å½•å®Œæ•´çš„APIè°ƒç”¨å‚æ•°
        import json
        logger.info(f"ğŸ“¤ å¢¨é—®APIåˆ›å»ºç¬”è®°è¯·æ±‚:")
        logger.info(f"URL: {url}")
        logger.info(f"Headers: {self.headers}")
        logger.info(f"Payload: {json.dumps(payload, indent=2, ensure_ascii=False)}")
            
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=self.headers, json=payload)
            logger.info(f"ğŸ“¥ å¢¨é—®APIå“åº”çŠ¶æ€: {response.status_code}")
            logger.info(f"ğŸ“¥ å¢¨é—®APIå“åº”å†…å®¹: {response.text}")
            response.raise_for_status()
            return response.json()
    
    async def edit_note(self, note_id: str, body: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç¼–è¾‘ç¬”è®°
        
        å‚æ•°:
        - note_id: ç¬”è®°ID
        - body: æ–°çš„ç¬”è®°å†…å®¹ï¼ˆNoteAtomç»“æ„ï¼‰
        """
        url = urljoin(self.base_url, "/api/open/api/v1/note/edit")
        payload = {
            "noteId": note_id,
            "body": body
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            return response.json()
    
    async def set_note_privacy(self, note_id: str, privacy_type: str, rule: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è®¾ç½®ç¬”è®°éšç§
        
        å‚æ•°:
        - note_id: ç¬”è®°ID
        - privacy_type: éšç§ç±»å‹ (public/private/rule)
        - rule: éšç§è§„åˆ™ï¼ˆå¯é€‰ï¼‰
        """
        url = urljoin(self.base_url, "/api/open/api/v1/note/set")
        privacy_settings = {"type": privacy_type}
        if rule:
            privacy_settings["rule"] = rule
            
        payload = {
            "noteId": note_id,
            "section": 1,  # 1è¡¨ç¤ºç¬”è®°éšç§è®¾ç½®
            "settings": {
                "privacy": privacy_settings
            }
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            return response.json()
    
    async def reset_api_key(self) -> Dict[str, Any]:
        """é‡ç½®APIå¯†é’¥"""
        url = urljoin(self.base_url, "/api/open/api/v1/auth/key/reset")
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=self.headers, json={})
            response.raise_for_status()
            return response.json()
    
    async def get_upload_auth(self, file_type: int, file_name: str) -> Dict[str, Any]:
        """
        è·å–ä¸Šä¼ æˆæƒä¿¡æ¯
        
        å‚æ•°:
        - file_type: æ–‡ä»¶ç±»å‹ (1=å›¾ç‰‡, 2=éŸ³é¢‘, 3=PDF)
        - file_name: æ–‡ä»¶å
        """
        url = urljoin(self.base_url, "/api/open/api/v1/upload/prepare")
        payload = {
            "fileType": file_type,
            "fileName": file_name
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            return response.json()
    
    async def upload_file_local(self, auth_info: Dict[str, Any], file_path: str) -> Dict[str, Any]:
        """
        æœ¬åœ°æ–‡ä»¶ä¸Šä¼ 
        
        å‚æ•°:
        - auth_info: ä¸Šä¼ æˆæƒä¿¡æ¯
        - file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
        """
        form_info = auth_info["form"]
        endpoint = form_info["endpoint"]
        form_data = form_info
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        async with aiofiles.open(file_path, 'rb') as f:
            file_content = await f.read()
        
        # æ„å»ºmultipart/form-data
        files = {"file": (Path(file_path).name, file_content)}
        data = {k: v for k, v in form_data.items() if k != "file"}
        
        async with httpx.AsyncClient(timeout=300.0) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
            response = await client.post(endpoint, data=data, files=files)
            response.raise_for_status()
            return response.json()
    
    async def upload_file_url(self, file_type: int, url: str, file_name: Optional[str] = None) -> Dict[str, Any]:
        """
        è¿œç¨‹URLæ–‡ä»¶ä¸Šä¼ 
        
        å‚æ•°:
        - file_type: æ–‡ä»¶ç±»å‹ (1=å›¾ç‰‡, 2=éŸ³é¢‘, 3=PDF)
        - url: æ–‡ä»¶URL
        - file_name: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        """
        api_url = urljoin(self.base_url, "/api/open/api/v1/upload/url")
        payload = {
            "fileType": file_type,
            "url": url
        }
        if file_name:
            payload["fileName"] = file_name
            
        async with httpx.AsyncClient(timeout=300.0) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
            response = await client.post(api_url, headers=self.headers, json=payload)
            response.raise_for_status()
            return response.json()

class NoteAtomBuilder:
    """NoteAtomç»“æ„æ„å»ºå™¨ï¼Œå¸®åŠ©æ„å»ºç¬¦åˆå¢¨é—®æ ¼å¼çš„ç¬”è®°å†…å®¹"""
    
    @staticmethod
    def create_doc(paragraphs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡æ¡£æ ¹èŠ‚ç‚¹"""
        return {
            "type": "doc",
            "content": paragraphs
        }
    
    @staticmethod
    def create_paragraph(texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºæ®µè½èŠ‚ç‚¹"""
        if not texts:
            return {"type": "paragraph"}
        return {
            "type": "paragraph", 
            "content": texts
        }
    
    @staticmethod
    def create_quote(texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºå¼•ç”¨èŠ‚ç‚¹"""
        if not texts:
            return {"type": "quote"}
        return {
            "type": "quote",
            "content": texts
        }
    
    @staticmethod
    def create_note(note_uuid: str) -> Dict[str, Any]:
        """åˆ›å»ºå†…é“¾ç¬”è®°èŠ‚ç‚¹"""
        return {
            "type": "note",
            "attrs": {
                "uuid": note_uuid
            }
        }
    
    @staticmethod
    def create_text(text: str, marks: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡æœ¬èŠ‚ç‚¹"""
        node = {
            "type": "text",
            "text": text
        }
        if marks:
            node["marks"] = marks
        return node
    
    @staticmethod
    def create_bold_mark() -> Dict[str, Any]:
        """åˆ›å»ºåŠ ç²—æ ‡è®°"""
        return {"type": "bold"}
    
    @staticmethod  
    def create_highlight_mark() -> Dict[str, Any]:
        """åˆ›å»ºé«˜äº®æ ‡è®°"""
        return {"type": "highlight"}
    
    @staticmethod
    def create_link_mark(href: str) -> Dict[str, Any]:
        """åˆ›å»ºé“¾æ¥æ ‡è®°"""
        return {
            "type": "link",
            "attrs": {"href": href}
        }
    
    @staticmethod
    def create_image(file_id: str, alt: str = "", align: str = "center") -> Dict[str, Any]:
        """åˆ›å»ºå›¾ç‰‡èŠ‚ç‚¹"""
        attrs = {"uuid": file_id}
        if alt:
            attrs["alt"] = alt
        if align:
            attrs["align"] = align
        return {
            "type": "image",
            "attrs": attrs
        }
    
    @staticmethod  
    def create_audio(file_id: str, show_note: str = "") -> Dict[str, Any]:
        """åˆ›å»ºéŸ³é¢‘èŠ‚ç‚¹"""
        attrs = {"audio-uuid": file_id}
        if show_note:
            attrs["show-note"] = show_note
        return {
            "type": "audio",
            "attrs": attrs
        }
    
    @staticmethod
    def create_pdf(file_id: str) -> Dict[str, Any]:
        """åˆ›å»ºPDFèŠ‚ç‚¹"""
        return {
            "type": "pdf",
            "attrs": {"uuid": file_id}
        }

# å…¨å±€APIå®¢æˆ·ç«¯å˜é‡
mowen_api: Optional[MowenAPI] = None

def get_mowen_api() -> MowenAPI:
    """è·å–æˆ–åˆå§‹åŒ–MowenAPIå®ä¾‹"""
    global mowen_api
    if mowen_api is None:
        api_key = os.getenv("MOWEN_API_KEY")
        if not api_key:
            raise RuntimeError("æœªè®¾ç½®APIå¯†é’¥ã€‚è¯·å…ˆè®¾ç½®MOWEN_API_KEYç¯å¢ƒå˜é‡ã€‚")
        mowen_api = MowenAPI(api_key)
    return mowen_api

# æ–‡ä»¶ç±»å‹æ˜ å°„
FILE_TYPE_MAP = {
    "image": 1,
    "audio": 2, 
    "pdf": 3
}

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {
    "image": {".gif", ".jpeg", ".jpg", ".png", ".webp"},
    "audio": {".mp3", ".mp4", ".m4a"},
    "pdf": {".pdf"}
}

# æ–‡ä»¶å¤§å°é™åˆ¶ (å­—èŠ‚)
FILE_SIZE_LIMITS = {
    "image": 50 * 1024 * 1024,  # 50MB
    "audio": 200 * 1024 * 1024,  # 200MB
    "pdf": 100 * 1024 * 1024   # 100MB
}

def get_file_type_from_extension(file_path: str) -> Optional[str]:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ–‡ä»¶ç±»å‹"""
    ext = Path(file_path).suffix.lower()
    
    for file_type, extensions in SUPPORTED_EXTENSIONS.items():
        if ext in extensions:
            return file_type
    return None

def normalize_file_path(file_path: str) -> str:
    """
    æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿå’Œå®¢æˆ·ç«¯ä¼ å…¥çš„è·¯å¾„æ ¼å¼
    
    ä¸»è¦å¤„ç†ï¼š
    1. æ­£æ–œæ å’Œåæ–œæ çš„ç»Ÿä¸€
    2. è·¯å¾„åˆ†éš”ç¬¦çš„æ ‡å‡†åŒ–
    3. ç›¸å¯¹è·¯å¾„è½¬ç»å¯¹è·¯å¾„
    4. å®¢æˆ·ç«¯è·¯å¾„å‰ç¼€å¼‚å¸¸ä¿®å¤ï¼ˆå¦‚å¤šä½™çš„@ç¬¦å·ï¼‰
    
    å‚æ•°:
    - file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
    
    è¿”å›: æ ‡å‡†åŒ–åçš„æ–‡ä»¶è·¯å¾„
    """
    if not file_path:
        return file_path
    
    try:
        # è®°å½•åŸå§‹è·¯å¾„
        logger.info(f"ğŸ”§ è·¯å¾„æ ‡å‡†åŒ– - åŸå§‹è·¯å¾„: {repr(file_path)}")
        
        # é¢„å¤„ç†ï¼šæ£€æŸ¥å¹¶ä¿®å¤å®¢æˆ·ç«¯è·¯å¾„å¼‚å¸¸
        cleaned_path = _clean_client_path_anomalies(file_path)
        if cleaned_path != file_path:
            logger.info(f"ğŸ”§ è·¯å¾„æ ‡å‡†åŒ– - å®¢æˆ·ç«¯å¼‚å¸¸ä¿®å¤: {repr(file_path)} -> {repr(cleaned_path)}")
        
        # ä½¿ç”¨pathlibè‡ªåŠ¨å¤„ç†è·¯å¾„åˆ†éš”ç¬¦
        # pathlibä¼šè‡ªåŠ¨å°†æ­£æ–œæ è½¬æ¢ä¸ºå½“å‰ç³»ç»Ÿçš„è·¯å¾„åˆ†éš”ç¬¦
        path = Path(cleaned_path)
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not path.is_absolute():
            path = path.resolve()
            logger.info(f"ğŸ”§ è·¯å¾„æ ‡å‡†åŒ– - ç›¸å¯¹è·¯å¾„è½¬ç»å¯¹è·¯å¾„: {path}")
        else:
            # å³ä½¿æ˜¯ç»å¯¹è·¯å¾„ï¼Œä¹Ÿè¿›è¡Œresolve()æ¥æ ‡å‡†åŒ–
            path = path.resolve()
        
        normalized_path = str(path)
        logger.info(f"ğŸ”§ è·¯å¾„æ ‡å‡†åŒ– - æœ€ç»ˆè·¯å¾„: {repr(normalized_path)}")
        
        return normalized_path
        
    except Exception as e:
        logger.warning(f"âš ï¸ è·¯å¾„æ ‡å‡†åŒ–å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
        # å¦‚æœæ ‡å‡†åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹è·¯å¾„
        return file_path

def _clean_client_path_anomalies(file_path: str) -> str:
    """
    æ¸…ç†å®¢æˆ·ç«¯ä¼ å…¥è·¯å¾„çš„å¼‚å¸¸æƒ…å†µ
    
    å¤„ç†å·²çŸ¥çš„å®¢æˆ·ç«¯è·¯å¾„é—®é¢˜ï¼š
    1. æ–‡ä»¶åå‰å¤šä½™çš„@ç¬¦å·
    2. å…¶ä»–å¯èƒ½çš„å‰ç¼€å¼‚å¸¸
    
    å‚æ•°:
    - file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
    
    è¿”å›: æ¸…ç†åçš„æ–‡ä»¶è·¯å¾„
    """
    if not file_path:
        return file_path
    
    original_path = file_path
    
    # æ£€æŸ¥æ–‡ä»¶åå‰æ˜¯å¦æœ‰å¤šä½™çš„@ç¬¦å·
    # ä¾‹å¦‚: "D:\\@note.png" -> "D:\\note.png"
    if '@' in file_path:
        # åˆ†ç¦»è·¯å¾„å’Œæ–‡ä»¶å
        path_obj = Path(file_path)
        parent_dir = path_obj.parent
        filename = path_obj.name
        
        # å¦‚æœæ–‡ä»¶åä»¥@å¼€å¤´ï¼Œå°è¯•ç§»é™¤@
        if filename.startswith('@'):
            cleaned_filename = filename[1:]  # ç§»é™¤ç¬¬ä¸€ä¸ª@å­—ç¬¦
            cleaned_path = str(parent_dir / cleaned_filename)
            
            logger.info(f"ğŸ”§ æ£€æµ‹åˆ°æ–‡ä»¶åå‰ç¼€@ç¬¦å·: {repr(filename)} -> {repr(cleaned_filename)}")
            return cleaned_path
    
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–å®¢æˆ·ç«¯å¼‚å¸¸çš„å¤„ç†é€»è¾‘
    # ä¾‹å¦‚ï¼šå¤„ç†å…¶ä»–ç‰¹æ®Šå‰ç¼€å­—ç¬¦
    
    return original_path

def validate_file_path(file_path: str) -> tuple[bool, str]:
    """
    éªŒè¯æ–‡ä»¶è·¯å¾„çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§
    
    è‡ªåŠ¨å¤„ç†è·¯å¾„æ ¼å¼å…¼å®¹æ€§ï¼š
    - æ”¯æŒæ­£æ–œæ å’Œåæ–œæ æ··ç”¨
    - è‡ªåŠ¨æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦
    - å…¼å®¹ä¸åŒå®¢æˆ·ç«¯çš„è·¯å¾„æ ¼å¼
    - è‡ªåŠ¨ä¿®å¤å®¢æˆ·ç«¯è·¯å¾„å¼‚å¸¸ï¼ˆå¦‚@å‰ç¼€ï¼‰
    
    è¿”å›: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    try:
        # é¦–å…ˆæ ‡å‡†åŒ–è·¯å¾„
        normalized_path = normalize_file_path(file_path)
        path = Path(normalized_path)
        
        logger.info(f"ğŸ” æ–‡ä»¶è·¯å¾„éªŒè¯ - æ ‡å‡†åŒ–è·¯å¾„: {normalized_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not path.exists():
            # å¦‚æœæ ‡å‡†åŒ–åçš„è·¯å¾„ä»ç„¶ä¸å­˜åœ¨ï¼Œå°è¯•é¢å¤–çš„ä¿®å¤ç­–ç•¥
            alternative_path = _try_alternative_path_fixes(file_path)
            if alternative_path and alternative_path != normalized_path:
                alt_path_obj = Path(alternative_path)
                if alt_path_obj.exists():
                    logger.info(f"ğŸ”§ ä½¿ç”¨æ›¿ä»£è·¯å¾„ä¿®å¤æˆåŠŸ: {alternative_path}")
                    path = alt_path_obj
                    normalized_path = alternative_path
                else:
                    # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬å°è¯•çš„æ‰€æœ‰è·¯å¾„
                    error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}"
                    if normalized_path != file_path:
                        error_msg += f"\næ ‡å‡†åŒ–åè·¯å¾„ï¼š{normalized_path}"
                    if alternative_path != normalized_path:
                        error_msg += f"\nå°è¯•çš„æ›¿ä»£è·¯å¾„ï¼š{alternative_path}"
                    error_msg += f"\nğŸ’¡ è¯·æ£€æŸ¥ï¼š\n  1. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\n  2. æ–‡ä»¶æ˜¯å¦ç¡®å®å­˜åœ¨\n  3. è·¯å¾„ä¸­æ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–å¼‚å¸¸å‰ç¼€"
                    return False, error_msg
            else:
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}"
                if normalized_path != file_path:
                    error_msg += f"\næ ‡å‡†åŒ–åè·¯å¾„ï¼š{normalized_path}"
                error_msg += f"\nğŸ’¡ è¯·æ£€æŸ¥ï¼š\n  1. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\n  2. æ–‡ä»¶æ˜¯å¦ç¡®å®å­˜åœ¨\n  3. è·¯å¾„ä¸­æ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–å¼‚å¸¸å‰ç¼€"
                return False, error_msg
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
        if not path.is_file():
            return False, f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶ï¼š{normalized_path}"
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_type = get_file_type_from_extension(str(path))
        if not file_type:
            supported = ", ".join([f"{ft}({', '.join(exts)})" for ft, exts in SUPPORTED_EXTENSIONS.items()])
            return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„ç±»å‹ï¼š{supported}"
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = path.stat().st_size
        size_limit = FILE_SIZE_LIMITS[file_type]
        if file_size > size_limit:
            size_mb = size_limit // (1024 * 1024)
            return False, f"æ–‡ä»¶è¿‡å¤§ã€‚{file_type}ç±»å‹æ–‡ä»¶æœ€å¤§æ”¯æŒ{size_mb}MB"
        
        logger.info(f"âœ… æ–‡ä»¶è·¯å¾„éªŒè¯é€šè¿‡: {normalized_path}")
        return True, ""
        
    except Exception as e:
        error_msg = f"æ–‡ä»¶è·¯å¾„éªŒè¯å¤±è´¥ï¼š{str(e)}"
        if file_path != normalize_file_path(file_path):
            error_msg += f"\nåŸå§‹è·¯å¾„ï¼š{file_path}\næ ‡å‡†åŒ–è·¯å¾„ï¼š{normalize_file_path(file_path)}"
        return False, error_msg

def _try_alternative_path_fixes(file_path: str) -> Optional[str]:
    """
    å°è¯•é¢å¤–çš„è·¯å¾„ä¿®å¤ç­–ç•¥
    
    å½“æ ‡å‡†åŒ–è·¯å¾„ä»ç„¶æ— æ•ˆæ—¶ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„ä¿®å¤æ–¹æ³•ï¼š
    1. ç›´æ¥ç§»é™¤æ–‡ä»¶åå‰çš„@ç¬¦å·ï¼ˆä¸é€šè¿‡æ ‡å‡†åŒ–ï¼‰
    2. å…¶ä»–å¯èƒ½çš„å®¢æˆ·ç«¯å¼‚å¸¸ä¿®å¤
    
    å‚æ•°:
    - file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
    
    è¿”å›: ä¿®å¤åçš„è·¯å¾„ï¼Œå¦‚æœæ— æ³•ä¿®å¤åˆ™è¿”å›None
    """
    if not file_path:
        return None
    
    # ç­–ç•¥1ï¼šç›´æ¥æ£€æŸ¥åŸå§‹è·¯å¾„ä¸­çš„@ç¬¦å·é—®é¢˜
    if '@' in file_path:
        # å°è¯•ç§»é™¤æ–‡ä»¶åä¸­çš„@ç¬¦å·
        path_obj = Path(file_path)
        parent_dir = path_obj.parent
        filename = path_obj.name
        
        if filename.startswith('@'):
            # ç§»é™¤@å‰ç¼€
            cleaned_filename = filename[1:]
            alternative_path = str(parent_dir / cleaned_filename)
            logger.info(f"ğŸ”§ å°è¯•æ›¿ä»£è·¯å¾„ä¿®å¤ - ç§»é™¤@å‰ç¼€: {repr(file_path)} -> {repr(alternative_path)}")
            return alternative_path
    
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–ä¿®å¤ç­–ç•¥
    # ä¾‹å¦‚ï¼šå¤„ç†å…¶ä»–å·²çŸ¥çš„å®¢æˆ·ç«¯å¼‚å¸¸æ¨¡å¼
    
    return None

async def process_file_upload(file_info: Dict[str, Any]) -> Dict[str, Any]:
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    
    å‚æ•°:
    - file_info: æ–‡ä»¶ä¿¡æ¯å­—å…¸
    
    è¿”å›: ä¸Šä¼ åçš„æ–‡ä»¶èŠ‚ç‚¹
    """
    file_type = file_info["file_type"]
    source_type = file_info["source_type"] 
    source_path = file_info["source_path"]
    metadata = file_info.get("metadata", {})
    
    logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶ä¸Šä¼ : {file_type}, {source_type}, {source_path}")
    
    # é¢„å…ˆæ£€æŸ¥APIå¯†é’¥
    try:
        get_mowen_api()  # è¿™ä¼šæŠ›å‡ºå¼‚å¸¸å¦‚æœAPIå¯†é’¥æœªè®¾ç½®
    except RuntimeError as e:
        raise ValueError(f"APIé…ç½®é”™è¯¯ï¼š{str(e)}ã€‚è¯·è®¾ç½®MOWEN_API_KEYç¯å¢ƒå˜é‡åé‡è¯•ã€‚")
    
    try:
        if source_type == "local":
            # æœ¬åœ°æ–‡ä»¶ä¸Šä¼ 
            is_valid, error_msg = validate_file_path(source_path)
            if not is_valid:
                raise ValueError(error_msg)
            
            # ä½¿ç”¨æ ‡å‡†åŒ–åçš„è·¯å¾„è¿›è¡Œæ–‡ä»¶æ“ä½œ
            normalized_path = normalize_file_path(source_path)
            file_path = Path(normalized_path)
            file_name = file_path.name
            file_type_code = FILE_TYPE_MAP[file_type]
            
            logger.info(f"ğŸ“ ä½¿ç”¨æ ‡å‡†åŒ–è·¯å¾„è¿›è¡Œæ–‡ä»¶ä¸Šä¼ : {normalized_path}")
            
            # è·å–ä¸Šä¼ æˆæƒ
            api_client = get_mowen_api()
            auth_result = await api_client.get_upload_auth(file_type_code, file_name)
            
            # æ‰§è¡Œæ–‡ä»¶ä¸Šä¼ ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–è·¯å¾„ï¼‰
            upload_result = await api_client.upload_file_local(auth_result, normalized_path)
            file_id = upload_result["file"]["fileId"]
            logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œè·å¾—æ–‡ä»¶ID: {file_id}")
            
        elif source_type == "url":
            # è¿œç¨‹URLä¸Šä¼ 
            file_type_code = FILE_TYPE_MAP[file_type]
            file_name = metadata.get("file_name")
            
            api_client = get_mowen_api()
            upload_result = await api_client.upload_file_url(file_type_code, source_path, file_name)
            file_id = upload_result["file"]["fileId"]
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¸Šä¼ ç±»å‹ï¼š{source_type}")
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹åˆ›å»ºç›¸åº”çš„èŠ‚ç‚¹
        if file_type == "image":
            alt = metadata.get("alt", "")
            align = metadata.get("align", "center")
            image_node = NoteAtomBuilder.create_image(file_id, alt, align)
            logger.info(f"ğŸ–¼ï¸ åˆ›å»ºå›¾ç‰‡èŠ‚ç‚¹: {image_node}")
            return image_node
        elif file_type == "audio":
            show_note = metadata.get("show_note", "")
            return NoteAtomBuilder.create_audio(file_id, show_note)
        elif file_type == "pdf":
            return NoteAtomBuilder.create_pdf(file_id)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_type}")
            
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise

async def process_paragraphs_with_files(paragraphs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    å¤„ç†åŒ…å«æ–‡ä»¶çš„æ®µè½åˆ—è¡¨ï¼Œå°†æ–‡ä»¶æ®µè½è½¬æ¢ä¸ºå®é™…çš„æ–‡ä»¶èŠ‚ç‚¹
    
    å‚æ•°:
    - paragraphs: æ®µè½åˆ—è¡¨
    
    è¿”å›: å¤„ç†åçš„æ®µè½åˆ—è¡¨
    """
    processed_paragraphs = []
    logger.info(f"ğŸ“ å¼€å§‹å¤„ç†æ®µè½ï¼Œæ€»æ•°: {len(paragraphs)}")
    
    for i, paragraph in enumerate(paragraphs):
        if paragraph.get("type") == "file":
            # è¿™æ˜¯ä¸€ä¸ªæ–‡ä»¶æ®µè½ï¼Œéœ€è¦ä¸Šä¼ æ–‡ä»¶å¹¶è½¬æ¢
            logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶æ®µè½ {i}: {paragraph}")
            try:
                file_node = await process_file_upload(paragraph)
                processed_paragraphs.append(file_node)
                logger.info(f"âœ… æ–‡ä»¶æ®µè½ {i} å¤„ç†å®Œæˆï¼Œç”ŸæˆèŠ‚ç‚¹: {file_node}")
            except Exception as e:
                # æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯æ®µè½
                logger.error(f"âŒ æ–‡ä»¶æ®µè½ {i} ä¸Šä¼ å¤±è´¥: {str(e)}")
                error_text = f"âš ï¸ æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼š{str(e)}"
                error_paragraph = NoteAtomBuilder.create_paragraph([
                    NoteAtomBuilder.create_text(error_text, [NoteAtomBuilder.create_highlight_mark()])
                ])
                processed_paragraphs.append(error_paragraph)
        else:
            # æ™®é€šæ®µè½ï¼Œç›´æ¥æ·»åŠ 
            logger.info(f"ğŸ“„ å¤„ç†æ™®é€šæ®µè½ {i}: {paragraph.get('type', 'paragraph')}")
            processed_paragraphs.append(paragraph)
    
    return processed_paragraphs

def run_async_safely(coro):
    """å®‰å…¨åœ°è¿è¡Œå¼‚æ­¥å‡½æ•°"""
    try:
        # å°è¯•åœ¨ç°æœ‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # ä½¿ç”¨ nest_asyncio å…è®¸åµŒå¥—
            return asyncio.run(coro)
        else:
            return loop.run_until_complete(coro)
    except RuntimeError:
        # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
        return asyncio.run(coro)

@mcp.tool()
def create_note(
    paragraphs: List[Dict[str, Any]] = Field(
        description="""
        å¯Œæ–‡æœ¬æ®µè½åˆ—è¡¨ï¼Œæ¯ä¸ªæ®µè½åŒ…å«å¤šä¸ªæ–‡æœ¬èŠ‚ç‚¹ã€‚æ”¯æŒæ–‡æœ¬ã€å¼•ç”¨ã€å†…é“¾ç¬”è®°å’Œæ–‡ä»¶ã€‚
        
        æ®µè½ç±»å‹ï¼š
        1. æ™®é€šæ®µè½ï¼ˆé»˜è®¤ï¼‰ï¼š{"texts": [...]}
        2. å¼•ç”¨æ®µè½ï¼š{"type": "quote", "texts": [...]}
        3. å†…é“¾ç¬”è®°ï¼š{"type": "note", "note_id": "ç¬”è®°ID"}
        4. æ–‡ä»¶æ®µè½ï¼š{"type": "file", "file_type": "image|audio|pdf", "source_type": "local|url", "source_path": "è·¯å¾„", "metadata": {...}}
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        [
            {
                "texts": [
                    {"text": "è¿™æ˜¯æ™®é€šæ–‡æœ¬"},
                    {"text": "è¿™æ˜¯åŠ ç²—æ–‡æœ¬", "bold": true},
                    {"text": "è¿™æ˜¯é«˜äº®æ–‡æœ¬", "highlight": true},
                    {"text": "è¿™æ˜¯é“¾æ¥", "link": "https://example.com"}
                ]
            },
            {
                "type": "quote",
                "texts": [
                    {"text": "è¿™æ˜¯å¼•ç”¨æ®µè½"},
                    {"text": "æ”¯æŒå¯Œæ–‡æœ¬", "bold": true}
                ]
            },
            {
                "type": "note",
                "note_id": "VPrWsE_-P0qwrFUOygGs8"
            },
            {
                "type": "file",
                "file_type": "image",
                "source_type": "local",
                "source_path": "/path/to/image.jpg",
                "metadata": {
                    "alt": "å›¾ç‰‡æè¿°",
                    "align": "center"
                }
            },
            {
                "type": "file",
                "file_type": "audio",
                "source_type": "url",
                "source_path": "https://example.com/audio.mp3",
                "metadata": {
                    "show_note": "00:00 å¼€åœº\\n01:30 ä¸»è¦å†…å®¹"
                }
            },
            {
                "texts": [
                    {"text": "ç¬¬äºŒæ®µå†…å®¹"}
                ]
            }
        ]
        
        æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š
        - å›¾ç‰‡(image): .gif, .jpeg, .jpg, .png, .webp (æœ€å¤§50MB)
        - éŸ³é¢‘(audio): .mp3, .mp4, .m4a (æœ€å¤§200MB)
        - PDF(pdf): .pdf (æœ€å¤§100MB)
        
        æ–‡ä»¶metadataè¯´æ˜ï¼š
        - å›¾ç‰‡: alt(æè¿°), align(å¯¹é½: left|center|right)
        - éŸ³é¢‘: show_note(ShowNoteå†…å®¹)
        - PDF: æ— éœ€é¢å¤–metadata
        
        ğŸ“ æ–‡ä»¶è·¯å¾„è¯´æ˜ï¼š
        - æ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼ˆæ¨èä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
        - è‡ªåŠ¨å…¼å®¹ä¸åŒæ“ä½œç³»ç»Ÿçš„è·¯å¾„æ ¼å¼ï¼š
          * Windowsåæ–œæ : "C:\\Users\\ç”¨æˆ·å\\Documents\\image.jpg"
          * æ­£æ–œæ æ ¼å¼: "C:/Users/ç”¨æˆ·å/Documents/image.jpg"  
          * macOS/Linux: "/Users/ç”¨æˆ·å/Documents/image.jpg"
          * æ··åˆæ ¼å¼: "C:/Users\\ç”¨æˆ·å/Documents\\image.jpg"
        - æ™ºèƒ½è·¯å¾„ä¿®å¤åŠŸèƒ½ï¼š
          * è‡ªåŠ¨ç§»é™¤æ–‡ä»¶åå‰çš„å¼‚å¸¸@ç¬¦å·: "D:\\@note.png" -> "D:\\note.png"
          * è‡ªåŠ¨æ ‡å‡†åŒ–è·¯å¾„æ ¼å¼ï¼Œè·¨å¹³å°å…¼å®¹
          * å¤šé‡ä¿®å¤ç­–ç•¥ç¡®ä¿è·¯å¾„æ­£ç¡®æ€§
        
        å¦‚æœåªæ˜¯ç®€å•æ–‡æœ¬ï¼Œå¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š
        [
            {
                "texts": [
                    {"text": "è¿™æ˜¯ä¸€æ®µç®€å•çš„æ–‡æœ¬å†…å®¹"}
                ]
            }
        ]
        """
    ),
    auto_publish: bool = Field(default=False, description="æ˜¯å¦è‡ªåŠ¨å‘å¸ƒç¬”è®°ã€‚Trueè¡¨ç¤ºç«‹å³å‘å¸ƒï¼ŒFalseè¡¨ç¤ºä¿å­˜ä¸ºè‰ç¨¿"),
    tags: Optional[List[str]] = Field(default=None, description="ç¬”è®°æ ‡ç­¾åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š['å·¥ä½œ', 'å­¦ä¹ ', 'é‡è¦']")
) -> str:
    """
    åˆ›å»ºä¸€ç¯‡æ–°çš„å¢¨é—®ç¬”è®°
    
    è¿™ä¸ªå·¥å…·ä½¿ç”¨ç»Ÿä¸€çš„å¯Œæ–‡æœ¬æ ¼å¼æ¥åˆ›å»ºç¬”è®°ï¼Œæ”¯æŒï¼š
    - å¤šä¸ªæ®µè½çš„ç»“æ„åŒ–å†…å®¹
    - æ™®é€šæ®µè½ï¼šæ–‡æœ¬æ ¼å¼ï¼ˆåŠ ç²—ã€é«˜äº®ã€é“¾æ¥ï¼‰
    - å¼•ç”¨æ®µè½ï¼šç”¨äºåˆ›å»ºå¼•ç”¨æ–‡æœ¬å—ï¼Œæ”¯æŒå¯Œæ–‡æœ¬æ ¼å¼
    - å†…é“¾ç¬”è®°ï¼šå¼•ç”¨å…¶ä»–ç¬”è®°ï¼Œåˆ›å»ºç¬”è®°é—´çš„å…³è”
    - çµæ´»çš„å†…å®¹ç»„ç»‡æ–¹å¼
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - å¿«é€Ÿè®°å½•æƒ³æ³•æˆ–å¤‡å¿˜å½•
    - åˆ›å»ºç»“æ„åŒ–æ–‡æ¡£
    - ä¿å­˜ä¼šè®®è®°å½•æˆ–å­¦ä¹ ç¬”è®°
    - åŒ…å«å¤–éƒ¨é“¾æ¥çš„ç¬”è®°
    
    ç®€å•æ–‡æœ¬ç¤ºä¾‹ï¼š
    create_note(
        paragraphs=[
            {
                "texts": [
                    {"text": "ä»Šå¤©å­¦ä¹ äº†Pythonç¼–ç¨‹ï¼Œé‡ç‚¹æ˜¯å¼‚æ­¥ç¼–ç¨‹æ¦‚å¿µ"}
                ]
            }
        ],
        auto_publish=True,
        tags=["å­¦ä¹ ", "Python", "ç¼–ç¨‹"]
    )
    
    å¯Œæ–‡æœ¬ç¤ºä¾‹ï¼š
    create_note(
        paragraphs=[
            {
                "texts": [
                    {"text": "é‡è¦æé†’ï¼š", "bold": true},
                    {"text": "æ˜å¤©çš„ä¼šè®®å·²æ”¹æœŸ"}
                ]
            },
            {
                "type": "quote",
                "texts": [
                    {"text": "è¯¦æƒ…è¯·æŸ¥çœ‹ï¼š", "highlight": true},
                    {"text": "ä¼šè®®é€šçŸ¥", "link": "https://example.com/meeting"}
                ]
            },
            {
                "type": "note",
                "note_id": "VPrWsE_-P0qwrFUOygGs8"
            }
        ],
        auto_publish=True,
        tags=["ä¼šè®®", "é€šçŸ¥"]
    )

    æ³¨æ„ï¼š
    åˆ›å»ºç¬”è®°æ—¶ï¼Œå°½é‡ä¸€æ¬¡æ€§ä¼ å…¥æ‰€æœ‰å†…å®¹ï¼Œé¿å…åˆ›å»ºåå†åˆ†å¤šæ¬¡è°ƒç”¨editæ¥å£
    """
    try:
        api_client = get_mowen_api()
    except RuntimeError as e:
        return f"é”™è¯¯ï¼š{str(e)}"
    
    # å‚æ•°éªŒè¯
    if not validate_rich_note_paragraphs(paragraphs):
        return """âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼
        
æ­£ç¡®çš„paragraphsæ ¼å¼ç¤ºä¾‹ï¼š
[
    {
        "texts": [
            {"text": "æ™®é€šæ–‡æœ¬"},
            {"text": "åŠ ç²—æ–‡æœ¬", "bold": true},
            {"text": "é«˜äº®æ–‡æœ¬", "highlight": true},
            {"text": "é“¾æ¥æ–‡æœ¬", "link": "https://example.com"}
        ]
    },
    {
        "type": "quote",
        "texts": [
            {"text": "å¼•ç”¨æ®µè½"}
        ]
    },
    {
        "type": "note",
        "note_id": "VPrWsE_-P0qwrFUOygGs8"
    }
]

è¯·æ£€æŸ¥ï¼š
1. æ™®é€šæ®µè½å’Œå¼•ç”¨æ®µè½å¿…é¡»æœ‰"texts"å­—æ®µ
2. å†…é“¾ç¬”è®°æ®µè½å¿…é¡»æœ‰"note_id"å­—æ®µ
3. æ¯ä¸ªæ–‡æœ¬èŠ‚ç‚¹å¿…é¡»æœ‰"text"å­—æ®µ
4. boldå’Œhighlightå¿…é¡»æ˜¯å¸ƒå°”å€¼
5. linkå¿…é¡»æ˜¯å­—ç¬¦ä¸²URL
6. note_idå¿…é¡»æ˜¯å­—ç¬¦ä¸²
"""
    
    if tags is None:
        tags = []
    
    try:
        # å…ˆå¤„ç†åŒ…å«æ–‡ä»¶çš„æ®µè½ï¼Œè¿›è¡Œæ–‡ä»¶ä¸Šä¼ 
        logger.info(f"ğŸš€ å¼€å§‹åˆ›å»ºç¬”è®°ï¼ŒåŸå§‹æ®µè½æ•°: {len(paragraphs)}")
        processed_paragraphs = run_async_safely(process_paragraphs_with_files(paragraphs))
        logger.info(f"ğŸ“‹ æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå¤„ç†åæ®µè½æ•°: {len(processed_paragraphs)}")
        
        # æ„å»ºå¯Œæ–‡æœ¬å†…å®¹
        paragraphs_built = []
        for para_data in processed_paragraphs:
            para_type = para_data.get("type", "paragraph")
            
            if para_type == "note":
                # å†…é“¾ç¬”è®°èŠ‚ç‚¹
                note_id = para_data.get("note_id")
                if not note_id:
                    raise ValueError("å†…é“¾ç¬”è®°èŠ‚ç‚¹å¿…é¡»æä¾›note_idå‚æ•°")
                paragraphs_built.append(NoteAtomBuilder.create_note(note_id))
            elif para_type in ["image", "audio", "pdf"]:
                # æ–‡ä»¶èŠ‚ç‚¹ï¼ˆå·²ç»é€šè¿‡process_paragraphs_with_fileså¤„ç†è¿‡ï¼‰
                paragraphs_built.append(para_data)
            elif "texts" in para_data:
                # æ–‡æœ¬æ®µè½ï¼ˆæ™®é€šæˆ–å¼•ç”¨ï¼‰
                texts = []
                for text_data in para_data["texts"]:
                    marks = []
                    if text_data.get("bold"):
                        marks.append(NoteAtomBuilder.create_bold_mark())
                    if text_data.get("highlight"):
                        marks.append(NoteAtomBuilder.create_highlight_mark())
                    if text_data.get("link"):
                        marks.append(NoteAtomBuilder.create_link_mark(text_data["link"]))
                    
                    text_node = NoteAtomBuilder.create_text(
                        text_data["text"], 
                        marks if marks else None
                    )
                    texts.append(text_node)
                
                if para_type == "quote":
                    paragraphs_built.append(NoteAtomBuilder.create_quote(texts))
                else:
                    paragraphs_built.append(NoteAtomBuilder.create_paragraph(texts))
            else:
                # å…¶ä»–ç±»å‹çš„æ®µè½ï¼Œå¯èƒ½æ˜¯å¤„ç†åçš„æ–‡ä»¶èŠ‚ç‚¹ç­‰ï¼Œç›´æ¥è·³è¿‡æˆ–è®°å½•é”™è¯¯
                logger.warning(f"æœªçŸ¥æ®µè½ç±»å‹: {para_data}")
        
        body = NoteAtomBuilder.create_doc(paragraphs_built)
        settings = {
            "autoPublish": auto_publish,
            "tags": tags
        }
        
        # è®°å½•æœ€ç»ˆå‘é€ç»™å¢¨é—®çš„å®Œæ•´æ•°æ®ç»“æ„
        import json
        logger.info(f"ğŸ—ï¸ æœ€ç»ˆæ„å»ºçš„ç¬”è®°ç»“æ„:")
        logger.info(f"Body: {json.dumps(body, indent=2, ensure_ascii=False)}")
        logger.info(f"Settings: {json.dumps(settings, indent=2, ensure_ascii=False)}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªé˜¶æ®µçš„æ®µè½æ•°
        logger.info(f"ğŸ“Š æ®µè½å¤„ç†ç»Ÿè®¡:")
        logger.info(f"  - åŸå§‹è¾“å…¥æ®µè½æ•°: {len(paragraphs)}")
        logger.info(f"  - æ–‡ä»¶å¤„ç†åæ®µè½æ•°: {len(processed_paragraphs)}")
        logger.info(f"  - æœ€ç»ˆæ„å»ºæ®µè½æ•°: {len(paragraphs_built)}")
        logger.info(f"  - æ¯ä¸ªæ„å»ºæ®µè½çš„ç±»å‹: {[p.get('type', 'unknown') for p in paragraphs_built]}")
        
        # ä½¿ç”¨ä¿®å¤çš„å¼‚æ­¥è¿è¡Œæ–¹å¼
        result = run_async_safely(api_client.create_note(body, settings))
            
        return f"âœ… ç¬”è®°åˆ›å»ºæˆåŠŸï¼\n\nç¬”è®°ID: {result.get('noteId', 'N/A')}\næ®µè½æ•°: {len(paragraphs_built)}\nè‡ªåŠ¨å‘å¸ƒ: {auto_publish}\næ ‡ç­¾: {', '.join(tags)}"
    except httpx.HTTPStatusError as e:
        error_detail = ""
        try:
            error_json = e.response.json()
            error_detail = f"\né”™è¯¯ä»£ç : {error_json.get('code', 'N/A')}\né”™è¯¯åŸå› : {error_json.get('reason', 'N/A')}\né”™è¯¯ä¿¡æ¯: {error_json.get('message', 'N/A')}"
        except:
            error_detail = f"\nHTTPçŠ¶æ€ç : {e.response.status_code}"
            
        return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}{error_detail}"
    except Exception as e:
        import traceback
        tb = traceback.format_exc()
        logger.error(f"åˆ›å»ºç¬”è®°æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\nå †æ ˆè·Ÿè¸ª: {tb}")
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}\n\nè°ƒè¯•ä¿¡æ¯:\n{tb}"

@mcp.tool()
def edit_note(
    note_id: str = Field(description="è¦ç¼–è¾‘çš„ç¬”è®°IDï¼Œé€šå¸¸æ˜¯åˆ›å»ºç¬”è®°æ—¶è¿”å›çš„ID"),
    paragraphs: List[Dict[str, Any]] = Field(
        description="""
        å¯Œæ–‡æœ¬æ®µè½åˆ—è¡¨ï¼Œæ¯ä¸ªæ®µè½åŒ…å«å¤šä¸ªæ–‡æœ¬èŠ‚ç‚¹ã€‚å°†å®Œå…¨æ›¿æ¢åŸæœ‰ç¬”è®°å†…å®¹ã€‚æ”¯æŒæ–‡æœ¬ã€å¼•ç”¨ã€å†…é“¾ç¬”è®°å’Œæ–‡ä»¶ã€‚
        
        æ®µè½ç±»å‹ï¼š
        1. æ™®é€šæ®µè½ï¼ˆé»˜è®¤ï¼‰ï¼š{"texts": [...]}
        2. å¼•ç”¨æ®µè½ï¼š{"type": "quote", "texts": [...]}
        3. å†…é“¾ç¬”è®°ï¼š{"type": "note", "note_id": "ç¬”è®°ID"}
        4. æ–‡ä»¶æ®µè½ï¼š{"type": "file", "file_type": "image|audio|pdf", "source_type": "local|url", "source_path": "è·¯å¾„", "metadata": {...}}
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        [
            {
                "texts": [
                    {"text": "è¿™æ˜¯æ™®é€šæ–‡æœ¬"},
                    {"text": "è¿™æ˜¯åŠ ç²—æ–‡æœ¬", "bold": true},
                    {"text": "è¿™æ˜¯é«˜äº®æ–‡æœ¬", "highlight": true},
                    {"text": "è¿™æ˜¯é“¾æ¥", "link": "https://example.com"}
                ]
            },
            {
                "type": "quote",
                "texts": [
                    {"text": "è¿™æ˜¯å¼•ç”¨æ®µè½"},
                    {"text": "æ”¯æŒå¯Œæ–‡æœ¬", "bold": true}
                ]
            },
            {
                "type": "note",
                "note_id": "VPrWsE_-P0qwrFUOygGs8"
            },
            {
                "type": "file",
                "file_type": "image",
                "source_type": "local",
                "source_path": "/path/to/image.jpg",
                "metadata": {
                    "alt": "å›¾ç‰‡æè¿°",
                    "align": "center"
                }
            },
            {
                "texts": [
                    {"text": "ç¬¬äºŒæ®µå†…å®¹"}
                ]
            }
        ]
        
        æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š
        - å›¾ç‰‡(image): .gif, .jpeg, .jpg, .png, .webp (æœ€å¤§50MB)
        - éŸ³é¢‘(audio): .mp3, .mp4, .m4a (æœ€å¤§200MB)
        - PDF(pdf): .pdf (æœ€å¤§100MB)
        
        æ–‡ä»¶metadataè¯´æ˜ï¼š
        - å›¾ç‰‡: alt(æè¿°), align(å¯¹é½: left|center|right)
        - éŸ³é¢‘: show_note(ShowNoteå†…å®¹)
        - PDF: æ— éœ€é¢å¤–metadata
        
        å¦‚æœåªæ˜¯ç®€å•æ–‡æœ¬ï¼Œå¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š
        [
            {
                "texts": [
                    {"text": "è¿™æ˜¯ä¸€æ®µç®€å•çš„æ–‡æœ¬å†…å®¹"}
                ]
            }
        ]
        """
    )
) -> str:
    """
    ç¼–è¾‘å·²å­˜åœ¨çš„ç¬”è®°å†…å®¹
    
    è¿™ä¸ªå·¥å…·ä½¿ç”¨ç»Ÿä¸€çš„å¯Œæ–‡æœ¬æ ¼å¼æ¥ç¼–è¾‘ç¬”è®°ï¼Œæ”¯æŒï¼š
    - å¤šä¸ªæ®µè½çš„ç»“æ„åŒ–å†…å®¹
    - æ™®é€šæ®µè½ï¼šæ–‡æœ¬æ ¼å¼ï¼ˆåŠ ç²—ã€é«˜äº®ã€é“¾æ¥ï¼‰
    - å¼•ç”¨æ®µè½ï¼šç”¨äºåˆ›å»ºå¼•ç”¨æ–‡æœ¬å—ï¼Œæ”¯æŒå¯Œæ–‡æœ¬æ ¼å¼
    - å†…é“¾ç¬”è®°ï¼šå¼•ç”¨å…¶ä»–ç¬”è®°ï¼Œåˆ›å»ºç¬”è®°é—´çš„å…³è”
    - çµæ´»çš„å†…å®¹ç»„ç»‡æ–¹å¼
    
    æ³¨æ„ï¼šæ­¤æ“ä½œä¼šå®Œå…¨æ›¿æ¢ç¬”è®°çš„åŸæœ‰å†…å®¹ï¼Œè€Œä¸æ˜¯è¿½åŠ å†…å®¹ã€‚
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - ä¿®æ­£ç¬”è®°ä¸­çš„é”™è¯¯
    - æ›´æ–°ç¬”è®°å†…å®¹
    - å°†ç®€å•æ–‡æœ¬ç¬”è®°å‡çº§ä¸ºå¯Œæ–‡æœ¬æ ¼å¼
    - é‡æ–°ç»„ç»‡ç¬”è®°ç»“æ„å’Œæ ¼å¼
    
    ç®€å•æ–‡æœ¬ç¤ºä¾‹ï¼š
    edit_note(
        note_id="note_123456",
        paragraphs=[
            {
                "texts": [
                    {"text": "æ›´æ–°åçš„ç¬”è®°å†…å®¹"}
                ]
            }
        ]
    )
    
    å¯Œæ–‡æœ¬ç¤ºä¾‹ï¼š
    edit_note(
        note_id="note_123456",
        paragraphs=[
            {
                "texts": [
                    {"text": "æ›´æ–°ï¼š", "bold": true},
                    {"text": "é¡¹ç›®è¿›åº¦å·²å®Œæˆ80%"}
                ]
            },
            {
                "type": "quote",
                "texts": [
                    {"text": "è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹ï¼š", "highlight": true},
                    {"text": "é¡¹ç›®æ–‡æ¡£", "link": "https://example.com/report"}
                ]
            },
            {
                "type": "note",
                "note_id": "VPrWsE_-P0qwrFUOygGs8"
            }
        ]
    )
    """
    try:
        api_client = get_mowen_api()
    except RuntimeError as e:
        return f"é”™è¯¯ï¼š{str(e)}"
    
    # å‚æ•°éªŒè¯
    if not validate_rich_note_paragraphs(paragraphs):
        return """âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼
        
æ­£ç¡®çš„paragraphsæ ¼å¼ç¤ºä¾‹ï¼š
[
    {
        "texts": [
            {"text": "æ™®é€šæ–‡æœ¬"},
            {"text": "åŠ ç²—æ–‡æœ¬", "bold": true},
            {"text": "é«˜äº®æ–‡æœ¬", "highlight": true},
            {"text": "é“¾æ¥æ–‡æœ¬", "link": "https://example.com"}
        ]
    },
    {
        "type": "quote",
        "texts": [
            {"text": "å¼•ç”¨æ®µè½"}
        ]
    },
    {
        "type": "note",
        "note_id": "VPrWsE_-P0qwrFUOygGs8"
    }
]

è¯·æ£€æŸ¥ï¼š
1. æ™®é€šæ®µè½å’Œå¼•ç”¨æ®µè½å¿…é¡»æœ‰"texts"å­—æ®µ
2. å†…é“¾ç¬”è®°æ®µè½å¿…é¡»æœ‰"note_id"å­—æ®µ
3. æ¯ä¸ªæ–‡æœ¬èŠ‚ç‚¹å¿…é¡»æœ‰"text"å­—æ®µ
4. boldå’Œhighlightå¿…é¡»æ˜¯å¸ƒå°”å€¼
5. linkå¿…é¡»æ˜¯å­—ç¬¦ä¸²URL
6. note_idå¿…é¡»æ˜¯å­—ç¬¦ä¸²
"""
    
    try:
        # å…ˆå¤„ç†åŒ…å«æ–‡ä»¶çš„æ®µè½ï¼Œè¿›è¡Œæ–‡ä»¶ä¸Šä¼ 
        processed_paragraphs = run_async_safely(process_paragraphs_with_files(paragraphs))
        
        # æ„å»ºå¯Œæ–‡æœ¬å†…å®¹
        paragraphs_built = []
        for para_data in processed_paragraphs:
            para_type = para_data.get("type", "paragraph")
            
            if para_type == "note":
                # å†…é“¾ç¬”è®°èŠ‚ç‚¹
                note_id = para_data.get("note_id")
                if not note_id:
                    raise ValueError("å†…é“¾ç¬”è®°èŠ‚ç‚¹å¿…é¡»æä¾›note_idå‚æ•°")
                paragraphs_built.append(NoteAtomBuilder.create_note(note_id))
            elif para_type in ["image", "audio", "pdf"]:
                # æ–‡ä»¶èŠ‚ç‚¹ï¼ˆå·²ç»é€šè¿‡process_paragraphs_with_fileså¤„ç†è¿‡ï¼‰
                paragraphs_built.append(para_data)
            elif "texts" in para_data:
                # æ–‡æœ¬æ®µè½ï¼ˆæ™®é€šæˆ–å¼•ç”¨ï¼‰
                texts = []
                for text_data in para_data["texts"]:
                    marks = []
                    if text_data.get("bold"):
                        marks.append(NoteAtomBuilder.create_bold_mark())
                    if text_data.get("highlight"):
                        marks.append(NoteAtomBuilder.create_highlight_mark())
                    if text_data.get("link"):
                        marks.append(NoteAtomBuilder.create_link_mark(text_data["link"]))
                    
                    text_node = NoteAtomBuilder.create_text(
                        text_data["text"], 
                        marks if marks else None
                    )
                    texts.append(text_node)
                
                if para_type == "quote":
                    paragraphs_built.append(NoteAtomBuilder.create_quote(texts))
                else:
                    paragraphs_built.append(NoteAtomBuilder.create_paragraph(texts))
            else:
                # å…¶ä»–ç±»å‹çš„æ®µè½ï¼Œå¯èƒ½æ˜¯å¤„ç†åçš„æ–‡ä»¶èŠ‚ç‚¹ç­‰ï¼Œç›´æ¥è·³è¿‡æˆ–è®°å½•é”™è¯¯
                logger.warning(f"æœªçŸ¥æ®µè½ç±»å‹: {para_data}")
        
        body = NoteAtomBuilder.create_doc(paragraphs_built)
        
        # ä½¿ç”¨ä¿®å¤çš„å¼‚æ­¥è¿è¡Œæ–¹å¼
        result = run_async_safely(api_client.edit_note(note_id, body))
            
        return f"âœ… ç¬”è®°ç¼–è¾‘æˆåŠŸï¼\n\nç¬”è®°ID: {result.get('noteId', note_id)}\næ®µè½æ•°: {len(paragraphs_built)}"
    except httpx.HTTPStatusError as e:
        error_detail = ""
        try:
            error_json = e.response.json()
            error_detail = f"\né”™è¯¯ä»£ç : {error_json.get('code', 'N/A')}\né”™è¯¯åŸå› : {error_json.get('reason', 'N/A')}\né”™è¯¯ä¿¡æ¯: {error_json.get('message', 'N/A')}"
        except:
            error_detail = f"\nHTTPçŠ¶æ€ç : {e.response.status_code}"
            
        return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}{error_detail}"
    except Exception as e:
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"


@mcp.tool()
def set_note_privacy(
    note_id: str = Field(description="ç¬”è®°ID"),
    privacy_type: Literal["public", "private", "rule"] = Field(
        description="""
        éšç§ç±»å‹ï¼š
        - 'public': å®Œå…¨å…¬å¼€ï¼Œä»»ä½•äººéƒ½å¯ä»¥è®¿é—®
        - 'private': ç§æœ‰ï¼Œåªæœ‰ä½œè€…å¯ä»¥è®¿é—®
        - 'rule': è§„åˆ™å…¬å¼€ï¼Œæ ¹æ®è‡ªå®šä¹‰è§„åˆ™æ§åˆ¶è®¿é—®
        """
    ),
    no_share: bool = Field(
        default=False, 
        description="å½“privacy_typeä¸º'rule'æ—¶ï¼Œæ˜¯å¦ç¦æ­¢åˆ†äº«ã€‚Trueè¡¨ç¤ºç¦æ­¢åˆ†äº«ï¼ŒFalseè¡¨ç¤ºå…è®¸åˆ†äº«"
    ),
    expire_at: int = Field(
        default=0, 
        description="å½“privacy_typeä¸º'rule'æ—¶ï¼Œè¿‡æœŸæ—¶é—´æˆ³ï¼ˆUnixæ—¶é—´æˆ³ï¼‰ã€‚0è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ"
    )
) -> str:
    """
    è®¾ç½®ç¬”è®°çš„éšç§æƒé™
    
    è¿™ä¸ªå·¥å…·ç”¨äºæ§åˆ¶ç¬”è®°çš„è®¿é—®æƒé™ï¼Œæ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
    
    1. å®Œå…¨å…¬å¼€ï¼ˆpublicï¼‰ï¼šä»»ä½•äººéƒ½å¯ä»¥è®¿é—®
    2. ç§æœ‰ï¼ˆprivateï¼‰ï¼šåªæœ‰ä½œè€…å¯ä»¥è®¿é—®
    3. è§„åˆ™å…¬å¼€ï¼ˆruleï¼‰ï¼šå¯ä»¥è®¾ç½®åˆ†äº«é™åˆ¶å’Œè¿‡æœŸæ—¶é—´
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - å°†è‰ç¨¿ç¬”è®°è®¾ä¸ºå…¬å¼€
    - ä¿æŠ¤æ•æ„Ÿä¿¡æ¯è®¾ä¸ºç§æœ‰
    - ä¸´æ—¶åˆ†äº«è®¾ç½®è¿‡æœŸæ—¶é—´
    
    ç¤ºä¾‹è°ƒç”¨ï¼š
    # è®¾ä¸ºå®Œå…¨å…¬å¼€
    set_note_privacy(note_id="note_123", privacy_type="public")
    
    # è®¾ä¸ºç§æœ‰
    set_note_privacy(note_id="note_123", privacy_type="private")
    
    # è®¾ä¸ºè§„åˆ™å…¬å¼€ï¼Œç¦æ­¢åˆ†äº«ï¼Œ1å°æ—¶åè¿‡æœŸ
    set_note_privacy(
        note_id="note_123", 
        privacy_type="rule", 
        no_share=True, 
        expire_at=1703980800
    )
    """
    try:
        api_client = get_mowen_api()
    except RuntimeError as e:
        return f"é”™è¯¯ï¼š{str(e)}"
    
    try:
        rule = None
        if privacy_type == "rule":
            rule = {
                "noShare": no_share,
                "expireAt": str(expire_at)
            }
        
        # ä½¿ç”¨ä¿®å¤çš„å¼‚æ­¥è¿è¡Œæ–¹å¼
        result = run_async_safely(api_client.set_note_privacy(note_id, privacy_type, rule))
        
        privacy_desc = {
            "public": "å®Œå…¨å…¬å¼€",
            "private": "ç§æœ‰",
            "rule": "è§„åˆ™å…¬å¼€"
        }
        
        response_text = f"âœ… ç¬”è®°éšç§è®¾ç½®æˆåŠŸï¼\n\nç¬”è®°ID: {note_id}\néšç§ç±»å‹: {privacy_desc.get(privacy_type, privacy_type)}"
        
        if rule:
            response_text += f"\nç¦æ­¢åˆ†äº«: {'æ˜¯' if rule['noShare'] else 'å¦'}"
            expire_time = rule['expireAt']
            if expire_time == "0":
                response_text += "\næœ‰æ•ˆæœŸ: æ°¸ä¹…"
            else:
                response_text += f"\nè¿‡æœŸæ—¶é—´æˆ³: {expire_time}"
                
        return response_text
    except httpx.HTTPStatusError as e:
        error_detail = ""
        try:
            error_json = e.response.json()
            error_detail = f"\né”™è¯¯ä»£ç : {error_json.get('code', 'N/A')}\né”™è¯¯åŸå› : {error_json.get('reason', 'N/A')}\né”™è¯¯ä¿¡æ¯: {error_json.get('message', 'N/A')}"
        except:
            error_detail = f"\nHTTPçŠ¶æ€ç : {e.response.status_code}"
            
        return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}{error_detail}"
    except Exception as e:
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"

@mcp.tool()
def reset_api_key() -> str:
    """
    é‡ç½®å¢¨é—®APIå¯†é’¥
    
    âš ï¸ è­¦å‘Šï¼šæ­¤æ“ä½œä¼šç«‹å³ä½¿å½“å‰APIå¯†é’¥å¤±æ•ˆï¼
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - APIå¯†é’¥æ³„éœ²éœ€è¦é‡ç½®
    - å®šæœŸæ›´æ¢å¯†é’¥æé«˜å®‰å…¨æ€§
    - å¯†é’¥ä¸¢å¤±éœ€è¦ç”Ÿæˆæ–°çš„
    
    æ³¨æ„äº‹é¡¹ï¼š
    1. æ‰§è¡Œåå½“å‰å¯†é’¥ç«‹å³å¤±æ•ˆ
    2. éœ€è¦ç«‹å³ä¿å­˜æ–°å¯†é’¥
    3. éœ€è¦æ›´æ–°æ‰€æœ‰ä½¿ç”¨è¯¥å¯†é’¥çš„åº”ç”¨
    
    ç¤ºä¾‹è°ƒç”¨ï¼š
    reset_api_key()
    """
    try:
        api_client = get_mowen_api()
    except RuntimeError as e:
        return f"é”™è¯¯ï¼š{str(e)}"
    
    try:
        # ä½¿ç”¨ä¿®å¤çš„å¼‚æ­¥è¿è¡Œæ–¹å¼
        result = run_async_safely(api_client.reset_api_key())
            
        new_api_key = result.get("apiKey", "N/A")
        
        return f"âš ï¸ APIå¯†é’¥é‡ç½®æˆåŠŸï¼\n\næ–°çš„APIå¯†é’¥: {new_api_key}\n\né‡è¦æé†’ï¼š\n1. è¯·ç«‹å³ä¿å­˜æ–°çš„APIå¯†é’¥\n2. æ—§çš„APIå¯†é’¥å·²ç«‹å³å¤±æ•ˆ\n3. éœ€è¦æ›´æ–°æ‚¨çš„åº”ç”¨é…ç½®"
    except httpx.HTTPStatusError as e:
        error_detail = ""
        try:
            error_json = e.response.json()
            error_detail = f"\né”™è¯¯ä»£ç : {error_json.get('code', 'N/A')}\né”™è¯¯åŸå› : {error_json.get('reason', 'N/A')}\né”™è¯¯ä¿¡æ¯: {error_json.get('message', 'N/A')}"
        except:
            error_detail = f"\nHTTPçŠ¶æ€ç : {e.response.status_code}"
            
        return f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}{error_detail}"
    except Exception as e:
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"

# æ·»åŠ å‚æ•°éªŒè¯è¾…åŠ©å‡½æ•°
def validate_rich_note_paragraphs(paragraphs: List[Dict[str, Any]]) -> bool:
    """éªŒè¯å¯Œæ–‡æœ¬ç¬”è®°æ®µè½æ ¼å¼"""
    try:
        for para in paragraphs:
            para_type = para.get("type", "paragraph")
            
            if para_type == "note":
                # å†…é“¾ç¬”è®°èŠ‚ç‚¹éªŒè¯
                if "note_id" not in para or not isinstance(para["note_id"], str):
                    return False
            elif para_type == "file":
                # æ–‡ä»¶æ®µè½éªŒè¯
                if "file_type" not in para or para["file_type"] not in ["image", "audio", "pdf"]:
                    return False
                if "source_type" not in para or para["source_type"] not in ["local", "url"]:
                    return False
                if "source_path" not in para or not isinstance(para["source_path"], str):
                    return False
                # metadataæ˜¯å¯é€‰çš„
                if "metadata" in para and not isinstance(para["metadata"], dict):
                    return False
            elif para_type in ["paragraph", "quote"] or "texts" in para:
                # æ–‡æœ¬æ®µè½éªŒè¯ï¼ˆæ™®é€šæ®µè½æˆ–å¼•ç”¨æ®µè½ï¼‰
                if "texts" not in para:
                    return False
                for text in para["texts"]:
                    if "text" not in text or not isinstance(text["text"], str):
                        return False
                    # éªŒè¯å¯é€‰å­—æ®µ
                    if "bold" in text and not isinstance(text["bold"], bool):
                        return False
                    if "highlight" in text and not isinstance(text["highlight"], bool):
                        return False
                    if "link" in text and not isinstance(text["link"], str):
                        return False
            # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯å¤„ç†åçš„æ–‡ä»¶èŠ‚ç‚¹ï¼Œè·³è¿‡éªŒè¯
        return True
    except:
        return False

def main():
    """ä¸»å‡½æ•°ï¼šå¯åŠ¨MCPæœåŠ¡å™¨"""
    global mowen_api
    
    # è·å–APIå¯†é’¥
    api_key = os.getenv("MOWEN_API_KEY")
    if not api_key:
        logger.error("æœªè®¾ç½®APIå¯†é’¥ã€‚è¯·å…ˆè®¾ç½®MOWEN_API_KEYç¯å¢ƒå˜é‡ã€‚")
        return
    
    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    mowen_api = MowenAPI(api_key)
    logger.info("å¢¨é—®APIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    # å¯åŠ¨æœåŠ¡å™¨
    logger.info("æ­£åœ¨å¯åŠ¨å¢¨é—®MCPæœåŠ¡å™¨...")
    mcp.run()

if __name__ == "__main__":
    main() 